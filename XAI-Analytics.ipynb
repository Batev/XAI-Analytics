{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XAI Analytics Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import xai\n",
    "import logging as log\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from shap import initjs\n",
    "from ipywidgets import Button, GridBox, Layout, ButtonStyle, Label, Dropdown, Text, Output, IntSlider, Checkbox\n",
    "from util.commons import *\n",
    "from util.ui import *\n",
    "from util.model import *\n",
    "from util.split import *\n",
    "from util.dataset import *\n",
    "from IPython.display import clear_output, display, HTML\n",
    "\n",
    "initjs()\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "It can be any unprocessed fact, value, text, sound or picture that is not being interpreted and analyzed.\n",
    "\n",
    "### Dataset Selection\n",
    "\n",
    "In this step one could either choose one of the predefined datasets or use an external dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataset_select_label = Label(layout=Layout(width='auto', height='auto'), value='Select a dataset (you can specify custom one by selecting other):')\n",
    "dataset_select_dropdown = Dropdown(options=[m.name for m in Datasets], value=None, layout=Layout(width='200px', height='auto'))\n",
    "name_url_text_label = Label(value='Provide dataset name and URL:')\n",
    "name_text = Text(description='Name: ', placeholder='e.g. Car Evaluation Data Set', disabled=True)\n",
    "url_text = Text(description='URL: ', placeholder='e.g. https://archive.ics.uci.edu/ml/machine-learning-databases/car/car.data', disabled=True)\n",
    "dataset_select_button = Button(description='Download dataset', layout=Layout(width='300px', height='auto'), style=ButtonStyle(button_color='green'), tooltip='Click me', icon='download', disabled=True)\n",
    "dataset_select_output = Output()\n",
    "\n",
    "display(dataset_select_label,\n",
    "        dataset_select_dropdown,\n",
    "        name_url_text_label,\n",
    "        name_text,\n",
    "        url_text,\n",
    "        dataset_select_button,\n",
    "        dataset_select_output)\n",
    "\n",
    "def on_value_change_dataset_select_dropdown(change):\n",
    "    dataset_select_output.clear_output()\n",
    "    global dataset\n",
    "    new_value = str(change['new'])\n",
    "    if new_value == 'other':\n",
    "        name_text.disabled=False\n",
    "        url_text.disabled=False\n",
    "        dataset_select_button.disabled=False\n",
    "    else:\n",
    "        name_text.disabled=True\n",
    "        url_text.disabled=True\n",
    "        dataset_select_button.disabled=True\n",
    "        dataset, msg = get_dataset(new_value)\n",
    "        with dataset_select_output:\n",
    "            display(msg)\n",
    "            display(dataset.df)\n",
    "            \n",
    "            \n",
    "def on_click_dataset_select_button(self):\n",
    "    dataset_select_output.clear_output()\n",
    "    global dataset\n",
    "    name = str(name_text.value)\n",
    "    url = str(url_text.value)\n",
    "    dataset, msg = get_dataset(name, url)\n",
    "    with dataset_select_output:\n",
    "        display(msg)\n",
    "        display(dataset.df)\n",
    "\n",
    "dataset_select_dropdown.observe(on_value_change_dataset_select_dropdown, names='value')\n",
    "dataset_select_button.on_click(on_click_dataset_select_button)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing (Optional)\n",
    "\n",
    "Data preprocessing is an integral step in the learning process as the quality of data and the useful information that can be derived from it directly affects the ability of our model to learn. Therefore, it can be helpfull to preprocess our data before feeding it into our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pandas.api.types import is_numeric_dtype, is_string_dtype\n",
    "\n",
    "strip_column_select_label = Label(layout=Layout(width='auto', height='auto'), value='Strip a column from the dataset:')\n",
    "strip_column_select_dropdown = Dropdown(options=list(dataset.df.columns), value=None, layout=Layout(width='220px', height='auto'))\n",
    "strip_button = Button(disabled=False, style=ButtonStyle(button_color='yellow'), tooltip='Strips everything except the selected value.', icon='bolt', layout=Layout(width='max-content', height='auto'))\n",
    "strip_column_output = Output()\n",
    "strip_column_output_inner = Output()\n",
    "\n",
    "# back up initial dataset\n",
    "df_backup = dataset.df\n",
    "\n",
    "#defaults for the cell\n",
    "eq_value = '='\n",
    "df_stripped = None\n",
    "\n",
    "def on_value_change_strip_column_select_dropdown(change):\n",
    "    strip_column_output.clear_output()\n",
    "    strip_column_output_inner.clear_output()\n",
    "    strip_button.description = ''\n",
    "    new_value = str(change['new'])\n",
    "    if is_numeric_dtype(dataset.df[new_value]):\n",
    "        eq_radio = init_strip_eq_radio(on_value_change_eq_radio)\n",
    "        min_val, max_val, step=calculate_slider_properties(dataset.df[new_value].unique())\n",
    "        value_slider = init_strip_value_slider(on_value_change_value_slider, min_val, max_val, step)\n",
    "        with strip_column_output:\n",
    "            display(eq_radio, value_slider, strip_button, strip_column_output_inner)\n",
    "    elif is_string_dtype(dataset.df[new_value]):\n",
    "        value_select_dropdown = init_strip_value_select_dropdown(on_value_change_value_select_dropdown, list(dataset.df[new_value].unique()))\n",
    "        with strip_column_output:\n",
    "            display(value_select_dropdown, strip_button, strip_column_output_inner)\n",
    "            \n",
    "def on_value_change_value_select_dropdown(change):\n",
    "    strip_column_output_inner.clear_output()\n",
    "    global df_stripped\n",
    "    new_value = str(change['new'])\n",
    "    with strip_column_output_inner:\n",
    "        strip_button.description='{} \\'{}\\''.format(strip_column_select_dropdown.value, new_value)\n",
    "        df_stripped = get_stripped_df(dataset.df, strip_column_select_dropdown.value, new_value)\n",
    "        display(df_stripped)\n",
    "\n",
    "def on_value_change_value_slider(change):\n",
    "    strip_column_output_inner.clear_output()\n",
    "    global df_stripped\n",
    "    new_value = float(str(change['new']))    \n",
    "    with strip_column_output_inner:\n",
    "        strip_button.description='{} {} \\'{}\\''.format(strip_column_select_dropdown.value, eq_value, new_value)\n",
    "        df_stripped = get_stripped_df(dataset.df, strip_column_select_dropdown.value, new_value, eq_value)\n",
    "        display(df_stripped)\n",
    "\n",
    "def on_value_change_eq_radio(change):\n",
    "    global eq_value\n",
    "    eq_value = str(change['new'])\n",
    "            \n",
    "def on_click_strip_button(self):\n",
    "    strip_column_output.clear_output()\n",
    "    global stack_label, df_stripped\n",
    "    dataset.df = df_stripped\n",
    "    dataset.df.reset_index(drop=True, inplace=True)\n",
    "    stack_label.value = stack_label.value + strip_button.description + ', ' \n",
    "    with strip_column_output:\n",
    "        display('{} selected successfully.'.format(strip_button.description), dataset.df)\n",
    "    \n",
    "def on_click_reset_button(self):\n",
    "    strip_column_output.clear_output()\n",
    "    dataset.df = df_backup\n",
    "    dataset.df.reset_index(drop=True, inplace=True)\n",
    "    global stack_label\n",
    "    stack_label.value = 'Stripped columns for the dataset: '\n",
    "    with strip_column_output:\n",
    "        display('Dataset restored to its initial state.', dataset.df)\n",
    "\n",
    "hbox = generate_reset_strip_hbox(on_click_reset_button)\n",
    "stack_label = get_reset_strip_hbox_label(hbox)\n",
    "    \n",
    "strip_column_select_dropdown.observe(on_value_change_strip_column_select_dropdown, names='value')\n",
    "strip_button.on_click(on_click_strip_button)\n",
    "\n",
    "display(hbox, strip_column_select_label, strip_column_select_dropdown, strip_column_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Visualization (Optional)\n",
    "\n",
    "Data visualization is the graphical representation of information and data. By using visual elements like charts, graphs, and maps, data visualization tools provide an accessible way to see and understand trends, outliers, and patterns in data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "show_imbalance_selectmultiple = SelectMultiple(options=list(dataset.df.columns), rows=len(list(dataset.df.columns)) if len(list(dataset.df.columns)) <= 20 else 20, layout=Layout(width='auto', height='auto'))\n",
    "show_imbalance_button = Button(description='Show imbalances', layout=Layout(width='auto', height='auto'), button_style='info', tooltip='Click me', icon='cubes')\n",
    "correlations_matrix_button = Button(description='Correlations as a hierarchical dendogram', tooltip='Click me', icon='sitemap', layout=Layout(width='auto', height='auto'), disabled=False, style=ButtonStyle(button_color='darkseagreen'))\n",
    "correlations_dendogram_button = Button(description='Correlations as a matrix', tooltip='Click me', icon='th-large', layout=Layout(width='auto', height='auto'), disabled=False, style=ButtonStyle(button_color='orange'))\n",
    "show_imbalance_output = Output()\n",
    "\n",
    "def on_click_show_imbalance_button(self):\n",
    "    show_imbalance_output.clear_output()\n",
    "    features_to_analyze = list(show_imbalance_selectmultiple.value)\n",
    "    with show_imbalance_output:\n",
    "        xai.imbalance_plot(dataset.df, *features_to_analyze)\n",
    "        \n",
    "def on_click_correlations_matrix_button(self):\n",
    "    show_imbalance_output.clear_output()\n",
    "    with show_imbalance_output:\n",
    "        display(xai.correlations(dataset.df, include_categorical=True, plot_type=\"matrix\"))\n",
    "        \n",
    "def on_click_correlations_dendogram_button(self):\n",
    "    show_imbalance_output.clear_output()\n",
    "    with show_imbalance_output:\n",
    "        display(xai.correlations(dataset.df, include_categorical=True))\n",
    "\n",
    "show_imbalance_button.on_click(on_click_show_imbalance_button)\n",
    "correlations_matrix_button.on_click(on_click_correlations_matrix_button)\n",
    "correlations_dendogram_button.on_click(on_click_correlations_dendogram_button)\n",
    "\n",
    "grid_box = generate_analyze_grid(show_imbalance_selectmultiple,\n",
    "                                 show_imbalance_button,\n",
    "                                 correlations_dendogram_button,\n",
    "                                 correlations_matrix_button)\n",
    "\n",
    "display(grid_box, show_imbalance_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting a Target\n",
    "\n",
    "Select a target for the models that later will be trained, interpreted and compared.\n",
    "> Note:\n",
    " * Classification is the task of predicting a discrete class label.\n",
    " * Regression is the task of predicting a continuous quantity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dropdown = Dropdown(options=list(dataset.df.columns), value=None, disabled=False)\n",
    "target_select_button = Button(description='Select target', disabled=False, button_style='success', tooltip='Click me', icon='mouse-pointer')\n",
    "target_output = Output()\n",
    "\n",
    "display(target_dropdown, target_select_button, target_output)\n",
    "\n",
    "def on_value_change_target_dropdown(change):\n",
    "    target_output.clear_output()\n",
    "    df_target, msg = show_target(dataset.df, change['new'])\n",
    "    with target_output:\n",
    "        display(df_target)\n",
    "\n",
    "def on_click_target_select_button(self):\n",
    "    target_output.clear_output()\n",
    "    global df_X, df_y\n",
    "    df_X, df_y, msg = split_feature_target(dataset.df, target_dropdown.value)\n",
    "    with target_output:\n",
    "        display(msg)\n",
    "\n",
    "target_dropdown.observe(on_value_change_target_dropdown, names='value')\n",
    "target_select_button.on_click(on_click_target_select_button)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Train up to ten models by using different properties and algorithms.\n",
    "\n",
    "> Note: Hover the mouse over the description of a property in order to get more information about it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "models_label = Label(layout=Layout(width='auto', height='auto'), value='Choose the number of models to be used: ')\n",
    "models_slider = IntSlider(value=1, min=1, max=8, step=1, disabled=False, continuous_update=False, orientation='horizontal', readout=True, readout_format='d')\n",
    "models_output = Output()\n",
    "\n",
    "def draw_grid():\n",
    "    display(generate_model_grid(\n",
    "        df_X,\n",
    "        number_of_models,\n",
    "        models,\n",
    "        on_click_feature_exclude_button=on_click_feature_exclude_button,\n",
    "        on_value_change_split_type_dropdown=on_value_change_split_type_dropdown,\n",
    "        on_click_model_train_button=on_click_model_train_button))\n",
    "\n",
    "def on_value_change_models_slider(change):\n",
    "    models_output.clear_output()\n",
    "    global number_of_models, models\n",
    "    number_of_models = change['new']\n",
    "    models, _ = fill_empty_models(df_X, df_y, number_of_models)\n",
    "    with models_output:\n",
    "        draw_grid()\n",
    "\n",
    "models_slider.observe(on_value_change_models_slider, names='value')\n",
    "display(models_label, models_slider, models_output)\n",
    "\n",
    "def on_value_change_split_type_dropdown(change):\n",
    "    model = get_model_by_split_type_dd(models, change['owner'])\n",
    "    _ = change_cross_columns_status(model, change['new'])\n",
    "\n",
    "def on_click_feature_exclude_button(self):\n",
    "    models_output.clear_output()\n",
    "    model = get_model_by_remove_features_button(models, self)\n",
    "    msg = remove_model_features(model)\n",
    "    with models_output:\n",
    "        draw_grid()\n",
    "\n",
    "def on_click_model_train_button(self):\n",
    "    model = get_model_by_train_model_button(models, self)\n",
    "    msg = fill_model(model)\n",
    "    with models_output:\n",
    "        display(msg)\n",
    "\n",
    "# initially show only one model\n",
    "with models_output:\n",
    "    number_of_models = 1\n",
    "    models, _ = fill_empty_models(df_X, df_y, number_of_models)\n",
    "\n",
    "    draw_grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Interpretations Methods\n",
    "\n",
    "Global model interpretability is about understanding how the model makes decisions, based on a holistic view of its features and each of the learned components such as weights, other parameters, and structures. It helps to understand the distribution of your target outcome based on the features.\n",
    "\n",
    "### Feature Importance\n",
    " \n",
    "Feature importance is generic term for the degree to which a predictive model relies on a particular feature. Generally, a feature’s importance is the increase in the model’s prediction error after we permuted the feature’s values. \n",
    "\n",
    "#### ELI5\n",
    "[ELI5](https://github.com/TeamHG-Memex/eli5) is a Python package which helps to debug machine learning classifiers and explain their predictions. It provides support for a wide variety of frameworks and packages and also implements several algorithms for inspecting black-box models.\n",
    " * ELI5's feature importance uses the simplest algorithm for feature importance. It just gives an explanation of estimator parameters (weights) for a given model.\n",
    "\n",
    "#### Skater\n",
    "[Skater](https://github.com/oracle/Skater)'s goal to demystify the inner workings of any type of predictive model that is language and framework agnostic. It supports algorithms to enable interpretability of supervised learning problems. The interpretation algorithms currently supported are post-hoc in nature. This approach helps us to apply interpretability to machine learning systems depending on the analytical use cases. The library has embraced object-oriented and functional programming paradigms as deemed necessary to provide scalability and concurrency while keeping code brevity in mind.\n",
    " * Skater's feature importance implementation is based on an information theoretic criteria. It measurs the entropy in the change of predictions, given a perturbation of a given feature. This means that the more a model’s decision depends on a feature, the more a prediction will change by perturbing this feature.\n",
    "\n",
    "#### SHAP\n",
    "[SHAP](https://github.com/slundberg/shap) (SHapley Additive exPlanations) is a game theoretic approach to explain the output of any machine learning model. It connects optimal credit allocation with local explanations using the classic Shapley values from game theory and their related extensions.\n",
    " * SHAP's feature importance uses a combination of feature contributions and game theory to come up with SHAP values. Then, it computes the global feature importance by taking the average of the SHAP value magnitudes across the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance_grid = generate_feature_importance_grid(models=models)\n",
    "feature_importance_button = Button(description='Generate feature importance plot(s)', disabled=False, layout=Layout(width='auto', height='auto'), button_style='info', tooltip='Click me', icon='bullseye')\n",
    "feature_importance_output = Output()\n",
    "explain_feature_importance_checkbox = Checkbox(value=False, description='Explain', disabled=False, indent=False)\n",
    "\n",
    "display(feature_importance_grid, explain_feature_importance_checkbox, feature_importance_button, feature_importance_output)\n",
    "\n",
    "def on_click_feature_importance_button(self):\n",
    "    feature_importance_output.clear_output()\n",
    "    type_value = get_child_value_by_description(feature_importance_grid, \"Type\", 0)\n",
    "    models_names = get_child_value_by_description(feature_importance_grid, \"Model(s)\", 0)\n",
    "    selected_models = get_models_by_names(models, models_names)\n",
    "    explain = explain_feature_importance_checkbox.value\n",
    "    for model in selected_models:\n",
    "        with feature_importance_output:\n",
    "            if type_value == 'SKATER':\n",
    "                plt.rcParams['figure.figsize'] = [14, 15]\n",
    "            else:\n",
    "                %matplotlib inline\n",
    "            plot = generate_feature_importance_plot(FeatureImportanceType[type_value], model)\n",
    "            if plot:\n",
    "                display(plot)\n",
    "    with feature_importance_output:\n",
    "        if explain:\n",
    "            print(generate_feature_importance_explanation(FeatureImportanceType[type_value], models))\n",
    "\n",
    "feature_importance_button.on_click(on_click_feature_importance_button)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partial Dependence Plot\n",
    "\n",
    "The partial dependence plot (short PDP or PD plot) shows the marginal effect one or two features have on the predicted outcome of a machine learning model. A partial dependence plot can show whether the relationship between the target and a feature is linear, monotonic or more complex. For example, when applied to a linear regression model, partial dependence plots always show a linear relationship.\n",
    "\n",
    "#### PDPBox\n",
    "[PDPBox](https://github.com/SauceCat/PDPbox)'s goal is to visualize the impact of certain features towards model prediction for any supervised learning algorithm.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pdp_grid = generate_pdp_grid(models=models)\n",
    "pdp_model_select_button = Button(description='Select model(s)', disabled=False, layout=Layout(width='auto', height='auto'), button_style='success', tooltip='Click me', icon='mouse-pointer')\n",
    "pdp_output = Output()\n",
    "# Inner output\n",
    "pdp_feature_selection_grid = None\n",
    "generate_pdp_plots_button = Button(description='Generate PDP plot(s)', disabled=False, layout=Layout(width='auto', height='auto'), button_style='info', tooltip='Click me', icon='bullseye')\n",
    "generate_pdp_output = Output()\n",
    "\n",
    "models_names = []\n",
    "\n",
    "display(pdp_grid, pdp_model_select_button, pdp_output)\n",
    "\n",
    "def on_click_pdp_model_select_button(self):\n",
    "    pdp_output.clear_output()\n",
    "    generate_pdp_output.clear_output()\n",
    "    global models_names\n",
    "    models_names = get_child_value_by_description(pdp_grid, \"Model(s)\", 0)\n",
    "    global pdp_feature_selection_grid\n",
    "    pdp_feature_selection_grid = generate_pdp_feature_selection_grid(get_models_by_names(models, models_names))\n",
    "    with pdp_output:\n",
    "        display(pdp_feature_selection_grid, generate_pdp_plots_button, generate_pdp_output)\n",
    "\n",
    "def on_click_generate_pdp_plots_button(self):\n",
    "    generate_pdp_output.clear_output()\n",
    "    type_value = get_child_value_by_description(pdp_grid, \"Type\", 0)\n",
    "    for model in models:\n",
    "        if model.name in models_names:\n",
    "            feature1 = get_child_value_by_description(pdp_feature_selection_grid, \"... \" + model.name, 0)\n",
    "            feature2 = get_child_value_by_description(pdp_feature_selection_grid, \"... \" + model.name, 1)\n",
    "            with generate_pdp_output:\n",
    "                generate_pdp_plots(PDPType[type_value], model, feature1, feature2)\n",
    "        \n",
    "pdp_model_select_button.on_click(on_click_pdp_model_select_button)\n",
    "generate_pdp_plots_button.on_click(on_click_generate_pdp_plots_button)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local Interpretation Methods\n",
    "\n",
    "Local interpretation focuses on specifics of each individual and provides explanations that can lead to a better understanding of the feature contribution in smaller groups of individuals that are often overlooked by the global interpretation techniques.\n",
    "\n",
    "#### SHAP\n",
    "[SHAP](https://github.com/slundberg/shap) (SHapley Additive exPlanations) leverages the idea of Shapley values for model feature influence scoring. The technical definition of a Shapley value is the “average marginal contribution of a feature value over all possible coalitions.” In other words, Shapley values consider all possible predictions for an instance using all possible combinations of inputs. Because of this exhaustive approach, SHAP can guarantee properties like consistency and local accuracy. LIME, on the other hand, does not offer such guarantees.\n",
    "\n",
    "#### LIME\n",
    "[LIME](https://github.com/marcotcr/lime) (Local Interpretable Model-agnostic Explanations) builds sparse linear models around each prediction to explain how the black box model works in that local vicinity. While treating the model as a black box, we perturb the instance we want to explain and learn a sparse linear model around it, as an explanation. LIME has the advantage over *SHAP*, that it is a lot faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "local_interpretation_grid = generate_local_interpretation_grid(models=models)\n",
    "generate_local_interpretation_button = Button(description='Generate a Local Interpretation(s)', disabled=False, layout=Layout(width='auto', height='auto'), button_style='info', tooltip='Click me', icon='bullseye')\n",
    "generate_local_interpretation_output = Output()\n",
    "explain_local_interpretation_checkbox = Checkbox(value=False, description='Explain', disabled=False, indent=False)\n",
    "\n",
    "display(local_interpretation_grid, explain_local_interpretation_checkbox, generate_local_interpretation_button, generate_local_interpretation_output)\n",
    "\n",
    "def on_click_generate_local_interpretation_button(self):\n",
    "    generate_local_interpretation_output.clear_output()\n",
    "    type_value = get_child_value_by_description(local_interpretation_grid, \"Type\", 0)\n",
    "    selected_models = get_models_by_names(models, get_child_value_by_description(local_interpretation_grid, \"Model(s)\", 0))\n",
    "    examples_type_value = get_child_value_by_description(local_interpretation_grid, \"Example(s) type:\", 0)\n",
    "    number_of_examples_value = get_child_value_by_description(local_interpretation_grid, \"Number of examples:\", 0)\n",
    "    explain = explain_local_interpretation_checkbox.value\n",
    "    \n",
    "    for model in selected_models:\n",
    "        examples = get_test_examples(model, ExampleType[examples_type_value], number_of_examples_value)\n",
    "        for example in examples:\n",
    "            with generate_local_interpretation_output:\n",
    "                print(get_example_information(model, example))\n",
    "                explanation = explain_single_instance(LocalInterpreterType[type_value], model, example)\n",
    "                if LocalInterpreterType[type_value] is LocalInterpreterType.LIME:\n",
    "                    explanation.show_in_notebook(show_table=True, show_all=True)\n",
    "                elif LocalInterpreterType[type_value] is LocalInterpreterType.SHAP:\n",
    "                    display(explanation)\n",
    "                if explain:\n",
    "                    print(generate_single_instance_explanation(LocalInterpreterType[type_value], model, example)) \n",
    "\n",
    "generate_local_interpretation_button.on_click(on_click_generate_local_interpretation_button)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
